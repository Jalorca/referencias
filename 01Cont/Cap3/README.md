# Patrones comunes de Data Pipelines
Diseñar un nuevo data pirpeline siempre es un nuevo vieje, las diferentes fuentes de datos y la amplia infraestructura presenta varias dificultades, desafios y oportunidades. Los pipelines son construidos con diferentes objetivos y restricciones. Los datos deben ser procesados casi a tiempo real, diariamente, modelados para el uso en un dashboard o como entrada para modelos de machine learning.

---
|Conceptos|Definiciones|
|---|---|
|ETL y ELT|Estos dos patrones son usados comunmente para data warehousing y business intelligence. Ests dos patrones consisten en 3 pasos, y su diferencia entre ellos es el orden de los 2 ultimos pasos. Extract/Extraer (E), consiste en recolectar de varias fuentes de datos en preparación para la carga y transformación. Load/Cargar (L), este paso trae ya sea la data bruto en caso de ELT o la data ya transformada en el caso de ETL a un data warehouse, data lake, o otro destino. Transform/Transformación (T) es donde la data en bruto de cada sistema fuente es combinada y formateada a una forma que es util para analisis, visualización o para lo que sea la pipeline.
|EtLT|Cuando ELT surgio como patron dominante, era comun hacer algunos procesos de tranformación despues de la extración y antes de la carga era util. Sin embrago estas transformaciones no se refieren a logica de negocios, modelado de data, las transformación estan limitadas a la exploración de los datos como: Eliminar rigistros duplicados, Analizar los parametros de URL en componentes individuales, Cubrir data sensible.|
|ELT para Analsiis de Datos|Este puede ser el mejor patron para construir data pipelines para trabajar con analisis de datos. Ya esta definido, base de datos en columnas son los mejores para manejar grandes volumenes de data. Tambien estas diseñados para manejar grandes columnas, tablas con muchas columnas.|
|ELT para Ciencia de datos|Los cientificos de datos necesitan acceder a data mas granular y a veces en bruto que los analistas de datos. Los cientificos de datos exploran la data y crean modelos predictivos.|
|ELT para productos de datos y Machine Learning| Los productos de datos, que muchas veces estan ligados a un modelo de machine learning, uqe necesitan entrenamiento y data de validación, esta data puede venir de varios fuentes y pasan por ciernto nivel de trnasformación para preparar su uso para el modelo.|
|> Pasos para una pipeline para machene learning|**INGESTA INGRESO DE DATOS:** Asegurar que la data esta preparada para modelo para luego ser usado para su entrenamiento y validación. **PREPROCESADO DE DATOS:** La data que ingressa bien puede no estar preparada para su uso en el desarrollo del modelo. Este paso es limpiada y preparada para los modelos. (Tokenizar, Caracterizar, convertir, normalizar). **mODEL TRAINING:** Despues de uqe la data es ingresada y preprocesada, el modelo necesita ser reentrenado. **DESPLIEGUE DE MODELO:** Desplegar el modelo puesde ser lo mas desafiante. Una data pipeline bien diseñada es la clave para mantener todo junto.|
|>Incorporar Retroalimentación en el pipeline| Cualquier modelos de ML tiene que incluir una proceso de recolección de retroalimentación para mejorar el modelo. Ayuda a saber si los resultados obtenidos son los precisos para los usuarios o si es necesario ajustar algunas cosas del modelo. Toda esa información puede ser ingresada nuevamente al data warehouse y incorporarlo en futuras versiones del modelo.|

---

